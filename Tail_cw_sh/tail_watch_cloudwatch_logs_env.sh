#!/usr/bin/env bash
set -euo pipefail

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 1) Carica .env (AWS creds + region)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
ENV_FILE="./.env"
if [[ ! -f "$ENV_FILE" ]]; then
  echo "ERRORE: non trovo '$ENV_FILE'." >&2
  exit 1
fi
set -a
. "$ENV_FILE"
set +a

: "${AWS_DEFAULT_REGION:?Devi definire AWS_DEFAULT_REGION nel tuo .env}"
: "${AWS_ACCESS_KEY_ID:?Devi definire AWS_ACCESS_KEY_ID nel tuo .env}"
: "${AWS_SECRET_ACCESS_KEY:?Devi definire AWS_SECRET_ACCESS_KEY nel tuo .env}"

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 2) Parametri
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
LOG_GROUP="/aws/eks/eks-tibco-test-cluster"
PATTERN="utility"
LIMIT=100

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 3) Recupera TUTTI i log-streams in JSON (auto-paginati)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
echo "ðŸ” Scarico tutti i log-stream di '$LOG_GROUP'â€¦"
TMP_JSON="$(mktemp)"
aws logs describe-log-streams \
  --log-group-name "$LOG_GROUP" \
  --order-by LastEventTime \
  --descending \
  --no-paginate \
  --output json \
  > "$TMP_JSON"

TOTAL=$(jq '.logStreams | length' "$TMP_JSON")
echo "ðŸ“‚ Trovati $TOTAL stream in totale."

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 4) Filtra con jq per contains("$PATTERN") e prendi il primo [0]
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
latest_stream=$(jq -r --arg pat "$PATTERN" '
  .logStreams
  | map(select(.logStreamName | contains($pat)))
  | .[0].logStreamName // empty
' "$TMP_JSON")

# Rimuovi il file temporaneo
rm -f "$TMP_JSON"

if [[ -z "$latest_stream" ]]; then
  echo "âš ï¸ Nessuno stream trovato con pattern '$PATTERN'." >&2
  exit 1
fi

echo "ðŸ“„ Stream selezionato: $latest_stream"
echo

convert_date(){
  local epoch_s=$1
  if [[ "$(uname)" == "Darwin" ]]; then
    date -r "$epoch_s" +"%Y-%m-%dT%H:%M:%S"
  else
    date -d "@$epoch_s" +"%Y-%m-%dT%H:%M:%S"
  fi
}

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 5) Se esiste `aws logs tail`, usalo col debug in ./logs/debug
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
if aws logs help tail >/dev/null 2>&1; then
  echo "â³ Facendo tail in realtime con 'aws logs tail'â€¦ (Ctrl+C per uscire)"

  # Abilita tracing solo per questo blocco
  set -x

  # Assicurati che la cartella esista
  mkdir -p logs/debug

  # Genera un nome univoco nella sottocartella locale
  TS=$(date +%Y%m%d%H%M%S)
  DBGLOG="$(mktemp logs/debug/aws-tail-debug.${TS}.log)"

  # Esegui il tail con --debug e salva tutto in DBGLOG, poi passa a jq
  aws logs tail "$LOG_GROUP" \
    --filter-pattern "$PATTERN" \
    --since 5h \
    --format detailed \
    --follow \
    --debug 2> "$DBGLOG" \
  | jq -r '.message | fromjson.log'

  # Disabilita tracing per il resto dello script
  set +x

  echo "â€” DEBUG LOG salvato in $DBGLOG â€”"
  exit 0
fi
